{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "#IMAGE_DIR = \"C:\\\\Users\\\\willi\\\\Documents\\\\Drexel\\\\Fall Quart 5\\\\MEM 679 - Machine Learning\\\\pokemon_images\\\\Pokemon_Dataset_Subset\"\n",
    "IMAGE_DIR = \"/home/jovyan/datapath/PokemonDataset_768By1666\"\n",
    "IMG_SIZE = (224, 224) #Images will be resized to 244 x 244\n",
    "BATCH_SIZE = 32 #Number of images to process at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse labels from filenames\n",
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Parses the filename to extract metadata.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the image file.\n",
    "\n",
    "    Returns:\n",
    "        pokemon_name (str): Name of Pokemon\n",
    "        shiny_form (int): 1 if Pokemon is shiny, 0 if Pokemon is Normal\n",
    "        gender (str): Gender of Pokemon\n",
    "\n",
    "    \"\"\"\n",
    "    parts = filename.replace('.jpg', '').split(' ')\n",
    "    location_name = parts[0]\n",
    "    shiny = 1 if 'Shiny' in parts else 0\n",
    "    gender = 'Unknown'\n",
    "    if 'Male & Female' in filename:\n",
    "        gender = 'Male & Female'\n",
    "    elif 'Male' in filename:\n",
    "        gender = 'Male'\n",
    "    elif 'Female' in filename:\n",
    "        gender = 'Female'\n",
    "    \n",
    "    location, name = location_name.split('_', 1)\n",
    "    \n",
    "    return name, shiny, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = []\n",
    "labels_name = []\n",
    "labels_shiny = []\n",
    "labels_gender = []\n",
    "\n",
    "for file in os.listdir(IMAGE_DIR):\n",
    "    if file.endswith((\".jpg\")):\n",
    "        filepath = os.path.join(IMAGE_DIR, file)\n",
    "        name, shiny, gender = parse_filename(file)\n",
    "        data.append(filepath)\n",
    "        labels_name.append(name)\n",
    "        labels_shiny.append(shiny)\n",
    "        labels_gender.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess labels\n",
    "unique_names = sorted(set(labels_name))\n",
    "unique_genders = [\"Male\", \"Female\", \"Male & Female\"]\n",
    "\n",
    "name_to_idx = {name: i for i, name in enumerate(unique_names)}\n",
    "gender_to_idx = {gender: i for i, gender in enumerate(unique_genders)}\n",
    "\n",
    "y_name = [name_to_idx[name] for name in labels_name]\n",
    "y_shiny = labels_shiny\n",
    "y_gender = [gender_to_idx[gender] for gender in labels_gender]\n",
    "\n",
    "# Split data\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    data, list(zip(y_name, y_shiny, y_gender)), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "'''\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "'''\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_images(filepaths, labels, batch_size):\n",
    "    def generator():\n",
    "        for filepath, label in zip(filepaths, labels):\n",
    "            # Load the image\n",
    "            image = tf.keras.utils.load_img(filepath)\n",
    "            image = tf.keras.utils.img_to_array(image) / 255.0\n",
    "            # Resize with padding\n",
    "            image = tf.image.resize_with_pad(image, target_height=IMG_SIZE[0], target_width=IMG_SIZE[1])\n",
    "            # Restructure labels into a dictionary for model outputs\n",
    "            label_dict = {\n",
    "                \"name_output\": label[0],\n",
    "                \"shiny_output\": label[1],\n",
    "                \"gender_output\": label[2]\n",
    "            }\n",
    "            yield image, label_dict\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(*IMG_SIZE, 3), dtype=tf.float32),\n",
    "            {\n",
    "                \"name_output\": tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "                \"shiny_output\": tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "                \"gender_output\": tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "            },\n",
    "        )\n",
    "    ).batch(batch_size)\n",
    "\n",
    "train_dataset = preprocess_images(train_data, train_labels, BATCH_SIZE)\n",
    "val_dataset = preprocess_images(val_data, val_labels, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_preprocessed_images(dataset, num_images=5):\n",
    "    \"\"\"\n",
    "    Visualizes a few random preprocessed images from the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: A TensorFlow Dataset object containing preprocessed images and labels.\n",
    "        num_images: Number of images to visualize.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, (image_batch, label_batch) in enumerate(dataset.take(1)):  # Take one batch from the dataset\n",
    "        for j in range(num_images):\n",
    "            plt.subplot(1, num_images, j + 1)\n",
    "            plt.imshow(image_batch[j].numpy())\n",
    "            plt.axis('off')\n",
    "            # Display the labels for the first image in the batch\n",
    "            label = label_batch\n",
    "            name = label[\"name_output\"][j].numpy()\n",
    "            shiny = \"Shiny\" if label[\"shiny_output\"][j].numpy() == 1 else \"Normal\"\n",
    "            gender = unique_genders[label[\"gender_output\"][j].numpy()]\n",
    "            plt.title(f\"{unique_names[name]}\\n{shiny}, {gender}\")\n",
    "        break  # Only process the first batch\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_preprocessed_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "x = Flatten()(base_model.output)\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dropout(0.5)(x)  # First dropout\n",
    "x = Dense(512, activation='relu')(x) #THESE WERE ADDITIONAL\n",
    "x = Dropout(0.3)(x)  # Second dropout #THESE WERE ADDITIONAL\n",
    "\n",
    "\n",
    "# Add regularization to the Dense layers\n",
    "name_output = Dense(len(unique_names), activation=\"softmax\", name=\"name_output\",\n",
    "                    kernel_regularizer=l2(0.02))(x)\n",
    "shiny_output = Dense(1, activation=\"sigmoid\", name=\"shiny_output\",\n",
    "                     kernel_regularizer=l2(0.02))(x)\n",
    "gender_output = Dense(len(unique_genders), activation=\"softmax\", name=\"gender_output\",\n",
    "                      kernel_regularizer=l2(0.02))(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=[name_output, shiny_output, gender_output])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"name_output\": \"categorical_crossentropy\",\n",
    "        \"shiny_output\": \"binary_crossentropy\",\n",
    "        \"gender_output\": \"categorical_crossentropy\",\n",
    "    },\n",
    "    metrics={\n",
    "        \"name_output\": [\"accuracy\"],\n",
    "        \"shiny_output\": [\"accuracy\"],\n",
    "        \"gender_output\": [\"accuracy\"],\n",
    "    },\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available devices\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "for device in physical_devices:\n",
    "    print(device)\n",
    "\n",
    "# Check if a GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available and being used.\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"name_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"shiny_output\": \"binary_crossentropy\",\n",
    "        \"gender_output\": \"sparse_categorical_crossentropy\",\n",
    "    },\n",
    "    metrics={\n",
    "        \"name_output\": [\"accuracy\"],\n",
    "        \"shiny_output\": [\"accuracy\"],\n",
    "        \"gender_output\": [\"accuracy\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2, patience=2, min_lr=1e-6\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    # Extract history metrics\n",
    "    history_dict = history.history\n",
    "\n",
    "    # Outputs to plot\n",
    "    outputs = ['name_output', 'shiny_output', 'gender_output']\n",
    "\n",
    "    # Create a separate plot for each output\n",
    "    for output in outputs:\n",
    "        train_acc = history_dict[f\"{output}_accuracy\"]\n",
    "        val_acc = history_dict[f\"val_{output}_accuracy\"]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_acc, label=f\"Train {output} Accuracy\")\n",
    "        plt.plot(val_acc, label=f\"Validation {output} Accuracy\")\n",
    "        plt.title(f\"Training vs. Validation Accuracy for {output.capitalize()}\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # Plot learning rate vs. epochs\n",
    "    if 'learning_rate' in history_dict:\n",
    "        learning_rate = history_dict['learning_rate']\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(learning_rate, label=\"Learning Rate\")\n",
    "        plt.title(\"Learning Rate vs. Epochs\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Learning Rate\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Call the function with your history object\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_predict(model_path, image_path, img_size, class_names, gender_labels):\n",
    "    \"\"\"\n",
    "    Loads a trained model from a .h5 file and predicts the Pokémon's details from an image.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the saved model (.h5 file).\n",
    "        image_path (str): Path to the image for prediction.\n",
    "        img_size (tuple): Target size for resizing the image (height, width).\n",
    "        class_names (list): List of Pokémon names corresponding to model output indices.\n",
    "        gender_labels (list): List of gender labels corresponding to model output indices.\n",
    "\n",
    "    Returns:\n",
    "        dict: Prediction results with Pokémon name, shiny status, and gender.\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "    # Preprocess the image (resizing with padding and normalization)\n",
    "    image = tf.keras.utils.load_img(image_path)\n",
    "    image_array = tf.keras.utils.img_to_array(image) / 255.0  # Normalize to [0, 1]\n",
    "    image_array = tf.image.resize_with_pad(image_array, target_height=img_size[0], target_width=img_size[1])\n",
    "    image_array = tf.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(image_array)\n",
    "\n",
    "    # Decode predictions\n",
    "    name_idx = tf.argmax(predictions[0], axis=1).numpy()[0]\n",
    "    shiny_status = int(predictions[1][0] > 0.5)  # Binary classification for shiny\n",
    "    gender_idx = tf.argmax(predictions[2], axis=1).numpy()[0]\n",
    "\n",
    "    # Prepare the result\n",
    "    result = {\n",
    "        \"name\": class_names[name_idx],\n",
    "        \"shiny\": \"Shiny\" if shiny_status == 1 else \"Normal\",\n",
    "        \"gender\": gender_labels[gender_idx]\n",
    "    }\n",
    "    return result\n",
    "\n",
    "#test_image_path = \"./Taj Mahal_Tyrantrum - Male & Female.jpg\"  # Replace with your test image path\n",
    "test_image_path = \"./BrotherAndPokemon.jpg\"  # Replace with your test image path\n",
    "model_path = \"pokemon_classifier_766By1666.h5\"\n",
    "\n",
    "prediction = load_model_and_predict(model_path, test_image_path, IMG_SIZE, unique_names, unique_genders)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PokemonIdentifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
