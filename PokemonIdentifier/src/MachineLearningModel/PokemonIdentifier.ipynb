{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datafed.CommandLib import API\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates Folder for Dataset\n",
    "try:\n",
    "    # Attempt to create a directory named 'datapath'\n",
    "    datapath = os.mkdir(\"./datapath\")\n",
    "    true_path = os.path.abspath(datapath)  # Get the absolute path of the created directory\n",
    "except:\n",
    "    # If the directory already exists, just use its path\n",
    "    datapath = \"./datapath\"\n",
    "    true_path = os.path.abspath(datapath)  # Get the absolute path of the existing directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the API object\n",
    "df_api = API()\n",
    "\n",
    "# Use the dataGet method to download data\n",
    "# \"d/525645423\" is the dataset identifier\n",
    "# os.path.abspath(datapath) provides the absolute path to the datapath directory\n",
    "# wait=True ensures the function waits for the download to complete\n",
    "dget_resp = df_api.dataGet(\"d/525645998\", os.path.abspath(datapath), wait=True)\n",
    "dget_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_folder(folder_path, zip_file_name, extract_to=None):\n",
    "    \"\"\"\n",
    "    Unzips a .zip file in the given folder and deletes the .zip file afterwards.\n",
    "    \n",
    "    folder_path: Path to the folder containing the .zip file.\n",
    "    zip_file_name: Name of the .zip file (with extension).\n",
    "    extract_to: Path to extract the contents to (default: same as folder_path).\n",
    "    \"\"\"\n",
    "    zip_path = os.path.join(folder_path, zip_file_name)  # Full path to the zip file\n",
    "    \n",
    "    # Default extraction path is the folder containing the zip file\n",
    "    if extract_to is None:\n",
    "        extract_to = folder_path\n",
    "    \n",
    "    # Check if the .zip file exists\n",
    "    if not os.path.exists(zip_path):\n",
    "        raise FileNotFoundError(f\"The file {zip_file_name} was not found in {folder_path}\")\n",
    "    \n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        print(f\"Extracted {zip_file_name} to {extract_to}\")\n",
    "    \n",
    "    try:\n",
    "        os.remove(zip_path)\n",
    "        print(f\"Deleted the zip file: {zip_file_name}\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error while deleting the zip file: {e}\")\n",
    "\n",
    "# Unzip the dataset\n",
    "zip_file_name = \"525645998.zip\"     # Name of Dataset Zipfile\n",
    "unzip_folder(true_path, zip_file_name) #Unzip Dataset\n",
    "images_path = os.path.join(true_path, \"Pokemon_Dataset_Correct\") #Creates absolute path to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "IMAGE_DIR = images_path #\n",
    "IMG_SIZE = (255, 255) \n",
    "BATCH_SIZE = 32 #Number of images to process at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse labels from filenames\n",
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Parses the filename to extract metadata.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the image file.\n",
    "\n",
    "    Returns:\n",
    "        pokemon_name (str): Name of Pokemon\n",
    "        shiny_form (int): 1 if Pokemon is shiny, 0 if Pokemon is Normal\n",
    "        gender (str): Gender of Pokemon\n",
    "\n",
    "    \"\"\"\n",
    "    parts = filename.replace('.jpg', '').split(' ')  # Remove the file extension and split by spaces\n",
    "    location_name = parts[0]  # Extract the location and name part\n",
    "    shiny = 1 if 'Shiny' in parts else 0  # Determine if the Pokémon is shiny\n",
    "    gender = 'Unknown'  # Default gender\n",
    "    if 'Male & Female' in filename:\n",
    "        gender = 'Male & Female'  # Check for both genders\n",
    "    elif 'Male' in filename:\n",
    "        gender = 'Male'  # Check for male gender\n",
    "    elif 'Female' in filename:\n",
    "        gender = 'Female'  # Check for female gender\n",
    "    \n",
    "    location, name = location_name.split('_', 1)  # Split location and name\n",
    "    \n",
    "    return name, shiny, gender  # Return the parsed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = []  # List to store file paths of images\n",
    "labels_name = []  # List to store Pokémon names\n",
    "labels_shiny = []  # List to store shiny status (1 for shiny, 0 for normal)\n",
    "labels_gender = []  # List to store gender of Pokémon\n",
    "\n",
    "# Iterate over each file in the image directory\n",
    "for file in os.listdir(IMAGE_DIR):\n",
    "    if file.endswith(\".jpg\"):  # Check if the file is a JPEG image\n",
    "        filepath = os.path.join(IMAGE_DIR, file)  # Get the full path of the image file\n",
    "        name, shiny, gender = parse_filename(file)  # Parse the filename to extract metadata\n",
    "        data.append(filepath)  # Add the file path to the data list\n",
    "        labels_name.append(name)  # Add the Pokémon name to the labels_name list\n",
    "        labels_shiny.append(shiny)  # Add the shiny status to the labels_shiny list\n",
    "        labels_gender.append(gender)  # Add the gender to the labels_gender list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess labels\n",
    "unique_names = sorted(set(labels_name))  # Get unique Pokémon names and sort them\n",
    "unique_genders = [\"Male\", \"Female\", \"Male & Female\"]  # Define unique gender labels\n",
    "\n",
    "# Create dictionaries to map names and genders to indices\n",
    "name_to_idx = {name: i for i, name in enumerate(unique_names)}\n",
    "gender_to_idx = {gender: i for i, gender in enumerate(unique_genders)}\n",
    "\n",
    "# Convert labels to indices\n",
    "y_name = [name_to_idx[name] for name in labels_name]  # Convert Pokémon names to indices\n",
    "y_shiny = labels_shiny  # Shiny status remains the same\n",
    "y_gender = [gender_to_idx[gender] for gender in labels_gender]  # Convert genders to indices\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    data, list(zip(y_name, y_shiny, y_gender)), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 42\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m image, label_dict\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_generator(\n\u001b[0;32m     31\u001b[0m         generator,\n\u001b[0;32m     32\u001b[0m         output_signature\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m         )\n\u001b[0;32m     40\u001b[0m     )\u001b[38;5;241m.\u001b[39mbatch(batch_size)\n\u001b[1;32m---> 42\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m preprocess_images(\u001b[43mtrain_data\u001b[49m, train_labels, BATCH_SIZE)\n\u001b[0;32m     43\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m preprocess_images(val_data, val_labels, BATCH_SIZE)    \n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Preprocess images\n",
    "#Initialize Augmentatio Parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_images(filepaths, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocesses images and labels for a machine learning model.\n",
    "\n",
    "    This function creates a TensorFlow dataset from a list of image file paths and corresponding labels.\n",
    "    It loads each image, resizes it with padding, normalizes pixel values, and structures the labels\n",
    "    into a dictionary format suitable for model outputs.\n",
    "\n",
    "    Args:\n",
    "        filepaths (list of str): List of file paths to the images.\n",
    "        labels (list of tuples): List of tuples where each tuple contains three elements:\n",
    "            - name_output (int): The label for the name output.\n",
    "            - shiny_output (int): The label for the shiny output.\n",
    "            - gender_output (int): The label for the gender output.\n",
    "        batch_size (int): The size of the batches to be generated.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: A TensorFlow dataset yielding batches of images and corresponding label dictionaries.\n",
    "    \"\"\"\n",
    "    def generator():\n",
    "        for filepath, label in zip(filepaths, labels):\n",
    "            # Load the image\n",
    "            image = tf.keras.utils.load_img(filepath)\n",
    "            image = tf.keras.utils.img_to_array(image) / 255.0 #Normalize pixel values\n",
    "            # Resize with padding\n",
    "            image = tf.image.resize_with_pad(image, target_height=IMG_SIZE[0], target_width=IMG_SIZE[1])\n",
    "            # Restructure labels into a dictionary for model outputs\n",
    "            label_dict = {\n",
    "                \"name_output\": label[0],\n",
    "                \"shiny_output\": label[1],\n",
    "                \"gender_output\": label[2]\n",
    "            }\n",
    "            yield image, label_dict  # Yield the image and label dictionary\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,  # Use the generator function to create the dataset\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(*IMG_SIZE, 3), dtype=tf.float32),  # Define the shape and type of the image tensor\n",
    "            {\n",
    "                \"name_output\": tf.TensorSpec(shape=(), dtype=tf.int32),  # Define the shape and type of the name output\n",
    "                \"shiny_output\": tf.TensorSpec(shape=(), dtype=tf.int32),  # Define the shape and type of the shiny output\n",
    "                \"gender_output\": tf.TensorSpec(shape=(), dtype=tf.int32),  # Define the shape and type of the gender output\n",
    "            },\n",
    "        )\n",
    "    ).batch(batch_size)  # Batch the dataset with the specified batch size\n",
    "\n",
    "train_dataset = preprocess_images(train_data, train_labels, BATCH_SIZE) #Create training dataset\n",
    "val_dataset = preprocess_images(val_data, val_labels, BATCH_SIZE)     #Creat Validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_preprocessed_images(dataset, num_images=5):\n",
    "    \"\"\"\n",
    "    Visualizes a few random preprocessed images from the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: A TensorFlow Dataset object containing preprocessed images and labels.\n",
    "        num_images: Number of images to visualize.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for image_batch, label_batch in dataset.take(1):  # Take one batch from the dataset\n",
    "        total_images = image_batch.shape[0]\n",
    "        random_indices = random.sample(range(total_images), num_images)  # Randomly select indices\n",
    "        for i, idx in enumerate(random_indices):\n",
    "            plt.subplot(1, num_images, i + 1)\n",
    "            plt.imshow(image_batch[idx].numpy())\n",
    "            plt.axis('off')\n",
    "            # Display the labels for the selected image\n",
    "            label = label_batch\n",
    "            name = label[\"name_output\"][idx].numpy()\n",
    "            shiny = \"Shiny\" if label[\"shiny_output\"][idx].numpy() == 1 else \"Normal\"\n",
    "            gender = unique_genders[label[\"gender_output\"][idx].numpy()]\n",
    "            plt.title(f\"{unique_names[name]}\\n{shiny}, {gender}\")\n",
    "        break  # Only process the first batch\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_preprocessed_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "# Load the EfficientNetB0 model without the top classification layer\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = Flatten()(base_model.output)\n",
    "\n",
    "# Add a dropout layer to reduce overfitting\n",
    "x = Dropout(0.5)(x)  # First dropout\n",
    "\n",
    "# Add a fully connected layer with ReLU activation\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add another dropout layer to reduce overfitting\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "# Add regularization to the Dense layers\n",
    "name_output = Dense(len(unique_names), activation=\"softmax\", name=\"name_output\",\n",
    "                    kernel_regularizer=l2(0.02))(x)  # Output layer for Pokémon names with L2 regularization\n",
    "shiny_output = Dense(1, activation=\"sigmoid\", name=\"shiny_output\",\n",
    "                     kernel_regularizer=l2(0.02))(x)  # Output layer for shiny status with L2 regularization\n",
    "gender_output = Dense(len(unique_genders), activation=\"softmax\", name=\"gender_output\",\n",
    "                      kernel_regularizer=l2(0.02))(x)  # Output layer for gender with L2 regularization\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=[name_output, shiny_output, gender_output])  # Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     loss\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshiny_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     },\n\u001b[0;32m      9\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshiny_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     13\u001b[0m     }\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     17\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m     18\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(\n\u001b[0;32m     22\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m\n\u001b[0;32m     23\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# Compile the model with appropriate loss functions and metrics\n",
    "model.compile(\n",
    "    optimizer=\"adam\",  # Use Adam optimizer\n",
    "    loss={\n",
    "        \"name_output\": \"sparse_categorical_crossentropy\",  # Loss for name classification\n",
    "        \"shiny_output\": \"binary_crossentropy\",  # Loss for shiny status classification\n",
    "        \"gender_output\": \"sparse_categorical_crossentropy\",  # Loss for gender classification\n",
    "    },\n",
    "    metrics={\n",
    "        \"name_output\": [\"accuracy\"],  # Accuracy metric for name classification\n",
    "        \"shiny_output\": [\"accuracy\"],  # Accuracy metric for shiny status classification\n",
    "        \"gender_output\": [\"accuracy\"],  # Accuracy metric for gender classification\n",
    "    }\n",
    ")\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Monitor validation loss\n",
    "    patience=3,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",  # Monitor validation loss\n",
    "    factor=0.2,  # Factor by which the learning rate will be reduced\n",
    "    patience=2,  # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    min_lr=1e-6  # Lower bound on the learning rate\n",
    ")\n",
    "\n",
    "\n",
    "# Train the model and store the training history\n",
    "history = model.fit(\n",
    "    train_dataset,  # Training dataset\n",
    "    validation_data=val_dataset,  # Validation dataset\n",
    "    epochs=50,  # Number of epochs to train\n",
    "    callbacks=[early_stopping, reduce_lr],  # List of callbacks for early stopping and learning rate reduction\n",
    "    verbose=1  # Verbosity mode (1 = progress bar)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the entire model\n",
    "model.save(\"pokemon_identifier_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy for different outputs and the learning rate over epochs.\n",
    "\n",
    "    Parameters:\n",
    "    history (keras.callbacks.History): A History object returned by the fit method of a Keras model. \n",
    "                                       It contains the training and validation metrics for each epoch.\n",
    "\n",
    "    The function will plot:\n",
    "    - Training and validation accuracy for 'name_output', 'shiny_output', and 'gender_output'.\n",
    "    - Learning rate over epochs if 'learning_rate' is present in the history.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Extract history metrics\n",
    "    history_dict = history.history\n",
    "\n",
    "    # Outputs to plot\n",
    "    outputs = ['name_output', 'shiny_output', 'gender_output']\n",
    "\n",
    "    # Create a separate plot for each output\n",
    "    for output in outputs:\n",
    "        train_acc = history_dict[f\"{output}_accuracy\"]  # Training accuracy for the current output\n",
    "        val_acc = history_dict[f\"val_{output}_accuracy\"]  # Validation accuracy for the current output\n",
    "\n",
    "        plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "        plt.plot(train_acc, label=f\"Train {output} Accuracy\")  # Plot training accuracy\n",
    "        plt.plot(val_acc, label=f\"Validation {output} Accuracy\")  # Plot validation accuracy\n",
    "        plt.title(f\"Training vs. Validation Accuracy for {output.capitalize()}\")  # Set the title\n",
    "        plt.xlabel(\"Epochs\")  # Set the x-axis label\n",
    "        plt.ylabel(\"Accuracy\")  # Set the y-axis label\n",
    "        plt.legend()  # Show the legend\n",
    "        plt.grid(True)  # Show the grid\n",
    "        plt.show()  # Display the plot\n",
    "\n",
    "    # Plot learning rate vs. epochs if learning rate is present in the history\n",
    "    if 'learning_rate' in history_dict:\n",
    "        learning_rate = history_dict['learning_rate']  # Extract learning rate\n",
    "        plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "        plt.plot(learning_rate, label=\"Learning Rate\")  # Plot learning rate\n",
    "        plt.title(\"Learning Rate vs. Epochs\")  # Set the title\n",
    "        plt.xlabel(\"Epochs\")  # Set the x-axis label\n",
    "        plt.ylabel(\"Learning Rate\")  # Set the y-axis label\n",
    "        plt.legend()  # Show the legend\n",
    "        plt.grid(True)  # Show the grid\n",
    "        plt.show()  # Display the plot\n",
    "\n",
    "# Call the function with your history object\n",
    "plot_training_history(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on a new image\n",
    "def predict_from_image(filepath, model, img_size, class_names, gender_labels):\n",
    "    \"\"\"\n",
    "    Predicts the Pokémon name, shiny status, and gender from an image, and visualizes preprocessing.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the image file.\n",
    "        model (tf.keras.Model): Trained model for predictions.\n",
    "        img_size (tuple): Image size expected by the model (height, width).\n",
    "        class_names (list): List of Pokémon names corresponding to indices.\n",
    "        gender_labels (list): List of gender labels corresponding to indices.\n",
    "\n",
    "    Returns:\n",
    "        dict: Prediction results containing name, shiny status, and gender.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = tf.keras.utils.load_img(filepath)\n",
    "    image_array = tf.keras.utils.img_to_array(image) / 255.0  # Normalize pixel values\n",
    "    \n",
    "    # Resize with padding (to preserve aspect ratio)\n",
    "    preprocessed_image = tf.image.resize_with_pad(image_array, img_size[0], img_size[1])\n",
    "    \n",
    "    # Add batch dimension\n",
    "    image_batch = tf.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(image_batch)\n",
    "\n",
    "    # Decode predictions\n",
    "    name_idx = tf.argmax(predictions[0], axis=1).numpy()[0]  # Get the index of the predicted Pokémon name\n",
    "    shiny_status = int(predictions[1][0] > 0.5)  # Determine shiny status (binary classification)\n",
    "    gender_idx = tf.argmax(predictions[2], axis=1).numpy()[0]  # Get the index of the predicted gender\n",
    "\n",
    "    # Prepare prediction results\n",
    "    result = {\n",
    "        \"name\": class_names[name_idx],\n",
    "        \"shiny\": \"Shiny\" if shiny_status == 1 else \"Normal\",\n",
    "        \"gender\": gender_labels[gender_idx],\n",
    "    }\n",
    "\n",
    "    # Display prediction on the image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(preprocessed_image.numpy())\n",
    "    plt.axis('off')\n",
    "    plt.title(\n",
    "        f\"Name: {result['name']}\\n\"\n",
    "        f\"Shiny Status: {result['shiny']}\\n\"\n",
    "        f\"Gender: {result['gender']}\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    return result\n",
    "\n",
    "# Testing Real Image\n",
    "dget_resp = df_api.dataGet(\"d/525646265\", os.path.abspath(datapath), wait=True)  # Download the image\n",
    "dget_resp\n",
    "actualImage_path = os.path.join(true_path, \"525646265.jpg\")  # Get the path to the downloaded image\n",
    "print(actualImage_path)\n",
    "\n",
    "# Predict and display the results\n",
    "prediction = predict_from_image(actualImage_path, model, IMG_SIZE, unique_names, unique_genders)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PokemonIdentifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
